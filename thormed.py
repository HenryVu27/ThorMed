# -*- coding: utf-8 -*-
"""Thormed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RzoI8Scf3MGRnCzsGydjI-Vb3y77FF6T

## 1. Setup and Imports
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/MyDrive/Thormed/Master')
print(f"Current working directory: {os.getcwd()}")

!pip install segmentation-models-pytorch albumentations

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
import segmentation_models_pytorch as smp

import numpy as np
import matplotlib.pyplot as plt
import cv2
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm.auto import tqdm
import glob
import os
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# Check GPU availability
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name()}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

"""## 2. Hyperparameter Configuration"""

# Hyperparameters
CONFIG = {
    # Data paths
    'images_path': 'data/images',
    'masks_path': 'data/masks',

    # Training parameters
    'batch_size': 8,
    'num_epochs': 60,
    'image_size': 256,
    'num_classes': 1,  # Binary segmentation

    # Optimizer parameters
    'learning_rate': 1e-4,
    'weight_decay': 1e-5,
    'betas': (0.9, 0.999),

    # Loss function weights
    'dice_weight': 0.4,
    'bce_weight': 0.6,

    # Data split
    'train_split': 0.8,
    'val_split': 0.2,

    # Training settings
    'num_workers': 2,
    'pin_memory': True,
    'mixed_precision': True,

    # Pretrained model architectures to finetune
    'models': {
        'UNet_ResNet18': {'encoder_name': 'resnet18', 'encoder_weights': 'imagenet'},
        'UNet_ResNet34': {'encoder_name': 'resnet34', 'encoder_weights': 'imagenet'},
        'UNet_EfficientNet_B0': {'encoder_name': 'efficientnet-b0', 'encoder_weights': 'imagenet'},
        'UNet_MobileNet_V2': {'encoder_name': 'mobilenet_v2', 'encoder_weights': 'imagenet'}
    },

    # Finetuning settings
    'freeze_encoder_epochs': 5,  # Freeze encoder for first N epochs
    'encoder_lr_factor': 0.1,   # Lower learning rate for encoder
    'warmup_epochs': 3,         # Gradual warmup
}

print("Configuration loaded:")
for key, value in CONFIG.items():
    if key != 'models':
        print(f"  {key}: {value}")
print(f"  models: {list(CONFIG['models'].keys())}")
print(f"\nFinetuning Strategy:")
print(f"  - Freeze encoder for {CONFIG['freeze_encoder_epochs']} epochs")
print(f"  - Encoder learning rate: {CONFIG['learning_rate'] * CONFIG['encoder_lr_factor']}")
print(f"  - Decoder learning rate: {CONFIG['learning_rate']}")

"""## 3. Dataset and Data Loading"""

class SegmentationDataset(Dataset):
    def __init__(self, images_dir, masks_dir, image_files, transform=None):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.image_files = image_files
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        # Load image
        img_name = self.image_files[idx]
        img_path = os.path.join(self.images_dir, img_name)
        image = cv2.imread(img_path)

        if image is None:
            raise ValueError(f"Failed to load image: {img_path}")

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Load mask - handle the _mask suffix pattern
        base_name = os.path.splitext(img_name)[0]

        # Primary mask path with _mask suffix
        mask_path = os.path.join(self.masks_dir, base_name + '_mask.png')
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if mask is None:
            # Try without _mask suffix as fallback
            mask_path = os.path.join(self.masks_dir, base_name + '.png')
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if mask is None:
            print(f"Warning: Could not load mask for {img_name}")
            print(f"Tried: {base_name}_mask.png and {base_name}.png")
            # Create dummy mask
            mask = np.zeros((256, 256), dtype=np.uint8)

        # Binarize mask
        mask = (mask > 127).astype(np.uint8)

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        return image.float(), mask.float().unsqueeze(0)

# Data augmentation
train_transform = A.Compose([
    A.Resize(CONFIG['image_size'], CONFIG['image_size']),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),
    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
    A.OneOf([
        A.ElasticTransform(p=0.3),
        A.GridDistortion(p=0.3),
        A.OpticalDistortion(p=0.3),
    ], p=0.3),
    A.CLAHE(p=0.3),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization
    ToTensorV2()
])

val_transform = A.Compose([
    A.Resize(CONFIG['image_size'], CONFIG['image_size']),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization
    ToTensorV2()
])

# Load file lists
image_files = [f for f in os.listdir(CONFIG['images_path']) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
print(f"Found {len(image_files)} images")

# Split data
train_files, val_files = train_test_split(
    image_files,
    train_size=CONFIG['train_split'],
    random_state=42
)

print(f"Training samples: {len(train_files)}")
print(f"Validation samples: {len(val_files)}")

# Create datasets
train_dataset = SegmentationDataset(
    CONFIG['images_path'], CONFIG['masks_path'], train_files, train_transform
)

val_dataset = SegmentationDataset(
    CONFIG['images_path'], CONFIG['masks_path'], val_files, val_transform
)

# Create data loaders
train_loader = DataLoader(
    train_dataset,
    batch_size=CONFIG['batch_size'],
    shuffle=True,
    num_workers=CONFIG['num_workers'],
    pin_memory=CONFIG['pin_memory']
)

val_loader = DataLoader(
    val_dataset,
    batch_size=CONFIG['batch_size'],
    shuffle=False,
    num_workers=CONFIG['num_workers'],
    pin_memory=CONFIG['pin_memory']
)

"""## 4. Pretrained U-Net Model Architectures"""

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def create_pretrained_unet(encoder_name, encoder_weights='imagenet', num_classes=1):
    model = smp.Unet(
        encoder_name=encoder_name,
        encoder_weights=encoder_weights,
        in_channels=3,
        classes=num_classes,
        activation='sigmoid'  # For binary segmentation
    )
    return model

def setup_finetuning_params(model, freeze_encoder=False, encoder_lr_factor=0.1, base_lr=1e-4):
    if freeze_encoder:
        # Freeze encoder parameters
        for param in model.encoder.parameters():
            param.requires_grad = False

        optimizer_params = [
            {'params': model.decoder.parameters(), 'lr': base_lr},
            {'params': model.segmentation_head.parameters(), 'lr': base_lr}
        ]
    else:
        # Different learning rates for encoder and decoder
        optimizer_params = [
            {'params': model.encoder.parameters(), 'lr': base_lr * encoder_lr_factor},
            {'params': model.decoder.parameters(), 'lr': base_lr},
            {'params': model.segmentation_head.parameters(), 'lr': base_lr}
        ]

    return optimizer_params

# Create all pretrained model architectures
models = {}
for name, config in CONFIG['models'].items():
    print(f"Loading {name} with encoder: {config['encoder_name']}")
    model = create_pretrained_unet(
        encoder_name=config['encoder_name'],
        encoder_weights=config['encoder_weights'],
        num_classes=CONFIG['num_classes']
    )

    param_count = count_parameters(model)
    models[name] = {
        'model': model,
        'params': param_count,
        'encoder_name': config['encoder_name'],
        'encoder_weights': config['encoder_weights']
    }

    print(f"{name}: {param_count/1e6:.2f}M parameters")

print(f"Successfully loaded {len(models)} pretrained models")

# Display encoder information
print("\nModel Details:")
print("-" * 60)
print(f"{'Model':<20} {'Encoder':<18} {'Params':<10} {'Weights':<12}")
print("-"*60)
for name, info in models.items():
    print(f"{name:<20} {info['encoder_name']:<18} {info['params']/1e6:>6.2f}M {info['encoder_weights']:<12}")

"""## 5. Loss Function (Combined Dice + BCE)"""

class DiceLoss(nn.Module):
    def __init__(self, smooth=1e-6):
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, predictions, targets):
        predictions = predictions.view(-1)
        targets = targets.view(-1)

        intersection = (predictions * targets).sum()
        dice_score = (2. * intersection + self.smooth) / (
            predictions.sum() + targets.sum() + self.smooth
        )

        return 1 - dice_score

class CombinedLoss(nn.Module):
    def __init__(self, dice_weight=0.4, bce_weight=0.6):
        super(CombinedLoss, self).__init__()
        self.dice_weight = dice_weight
        self.bce_weight = bce_weight
        self.dice_loss = DiceLoss()
        self.bce_loss = nn.BCELoss()

    def forward(self, predictions, targets):
        dice = self.dice_loss(predictions, targets)
        bce = self.bce_loss(predictions, targets)

        combined = self.dice_weight * dice + self.bce_weight * bce
        return combined, dice, bce

def calculate_iou(predictions, targets, threshold=0.5):
    predictions = (predictions > threshold).float()
    targets = targets.float()

    intersection = (predictions * targets).sum()
    union = predictions.sum() + targets.sum() - intersection

    if union == 0:
        return 1.0

    iou = intersection / union
    return iou.item()

def calculate_dice_score(predictions, targets, threshold=0.5):
    predictions = (predictions > threshold).float()
    targets = targets.float()

    intersection = (predictions * targets).sum()
    dice = (2. * intersection) / (predictions.sum() + targets.sum() + 1e-6)

    return dice.item()

print("Loss functions initialized")
print(f"Dice weight: {CONFIG['dice_weight']}")
print(f"BCE weight: {CONFIG['bce_weight']}")

"""## 6. Training Function"""

def train_model(model, model_name, train_loader, val_loader, num_epochs, device):
    model = model.to(device)

    criterion = CombinedLoss(
        dice_weight=CONFIG['dice_weight'],
        bce_weight=CONFIG['bce_weight']
    )

    # Initially freeze encoder
    for param in model.encoder.parameters():
        param.requires_grad = False

    # Decoder only initially
    optimizer_params = [
        {'params': model.decoder.parameters(), 'lr': CONFIG['learning_rate']},
        {'params': model.segmentation_head.parameters(), 'lr': CONFIG['learning_rate']}
    ]

    optimizer = optim.Adam(
        optimizer_params,
        weight_decay=CONFIG['weight_decay'],
        betas=CONFIG['betas']
    )

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', patience=7, factor=0.5, min_lr=1e-7
    )

    # Training history
    history = {
        'train_loss': [],
        'train_dice': [],
        'train_bce': [],
        'train_iou': [],
        'train_dice_score': [],
        'val_loss': [],
        'val_dice': [],
        'val_bce': [],
        'val_iou': [],
        'val_dice_score': [],
        'learning_rates': []
    }

    best_val_loss = float('inf')
    best_val_iou = 0.0

    print(f"\nFinetuning {model_name}...")
    print(f"Parameters: {count_parameters(model)/1e6:.2f}M")
    print(f"Encoder: {models[model_name]['encoder_name']} (pretrained on {models[model_name]['encoder_weights']})")
    print(f"Strategy: Freeze encoder for {CONFIG['freeze_encoder_epochs']} epochs, then unfreeze with lower LR")

    # Training loop with progressive unfreezing
    for epoch in range(num_epochs):
        # Unfreeze encoder after specified epochs
        if epoch == CONFIG['freeze_encoder_epochs']:
            print(f"\nUnfreezing encoder at epoch {epoch+1}")
            for param in model.encoder.parameters():
                param.requires_grad = True

            # Update optimizer with encoder parameters at lower learning rate
            optimizer_params = setup_finetuning_params(
                model,
                freeze_encoder=False,
                encoder_lr_factor=CONFIG['encoder_lr_factor'],
                base_lr=CONFIG['learning_rate']
            )
            optimizer = optim.Adam(
                optimizer_params,
                weight_decay=CONFIG['weight_decay'],
                betas=CONFIG['betas']
            )
            print(f"Encoder LR: {CONFIG['learning_rate'] * CONFIG['encoder_lr_factor']:.2e}")
            print(f"Decoder LR: {CONFIG['learning_rate']:.2e}")

        # Training phase
        model.train()
        train_losses = []
        train_dice_losses = []
        train_bce_losses = []
        train_ious = []
        train_dice_scores = []

        train_pbar = tqdm(
            train_loader,
            desc=f'Epoch {epoch+1:2d}/{num_epochs} [Train]',
            leave=False
        )

        for batch_idx, (images, masks) in enumerate(train_pbar):
            images = images.to(device)
            masks = masks.to(device)

            optimizer.zero_grad()

            # Forward pass
            outputs = model(images)
            loss, dice_loss, bce_loss = criterion(outputs, masks)

            # Backward pass
            loss.backward()

            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()

            # Calculate metrics
            iou = calculate_iou(outputs, masks)
            dice_score = calculate_dice_score(outputs, masks)

            train_losses.append(loss.item())
            train_dice_losses.append(dice_loss.item())
            train_bce_losses.append(bce_loss.item())
            train_ious.append(iou)
            train_dice_scores.append(dice_score)

            # Update progress bar
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'IoU': f'{iou:.4f}',
                'Dice': f'{dice_score:.4f}'
            })

        # Validation
        model.eval()
        val_losses = []
        val_dice_losses = []
        val_bce_losses = []
        val_ious = []
        val_dice_scores = []

        val_pbar = tqdm(
            val_loader,
            desc=f'Epoch {epoch+1:2d}/{num_epochs} [Val]  ',
            leave=False
        )

        with torch.no_grad():
            for images, masks in val_pbar:
                images = images.to(device)
                masks = masks.to(device)

                outputs = model(images)
                loss, dice_loss, bce_loss = criterion(outputs, masks)

                iou = calculate_iou(outputs, masks)
                dice_score = calculate_dice_score(outputs, masks)

                val_losses.append(loss.item())
                val_dice_losses.append(dice_loss.item())
                val_bce_losses.append(bce_loss.item())
                val_ious.append(iou)
                val_dice_scores.append(dice_score)

                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'IoU': f'{iou:.4f}',
                    'Dice': f'{dice_score:.4f}'
                })

        # Calculate epoch averages
        avg_train_loss = np.mean(train_losses)
        avg_train_dice = np.mean(train_dice_losses)
        avg_train_bce = np.mean(train_bce_losses)
        avg_train_iou = np.mean(train_ious)
        avg_train_dice_score = np.mean(train_dice_scores)

        avg_val_loss = np.mean(val_losses)
        avg_val_dice = np.mean(val_dice_losses)
        avg_val_bce = np.mean(val_bce_losses)
        avg_val_iou = np.mean(val_ious)
        avg_val_dice_score = np.mean(val_dice_scores)

        # Store history
        history['train_loss'].append(avg_train_loss)
        history['train_dice'].append(avg_train_dice)
        history['train_bce'].append(avg_train_bce)
        history['train_iou'].append(avg_train_iou)
        history['train_dice_score'].append(avg_train_dice_score)

        history['val_loss'].append(avg_val_loss)
        history['val_dice'].append(avg_val_dice)
        history['val_bce'].append(avg_val_bce)
        history['val_iou'].append(avg_val_iou)
        history['val_dice_score'].append(avg_val_dice_score)

        # Store current learning rate
        current_lr = optimizer.param_groups[0]['lr']
        history['learning_rates'].append(current_lr)

        # Learning rate scheduling
        scheduler.step(avg_val_loss)

        # Print epoch results
        status = "[FROZEN]" if epoch < CONFIG['freeze_encoder_epochs'] else "[ACTIVE]"
        print(f'{status} Epoch {epoch+1:3d}: '
              f'Train Loss: {avg_train_loss:.4f} | '
              f'Val Loss: {avg_val_loss:.4f} | '
              f'Val IoU: {avg_val_iou:.4f} | '
              f'Val Dice: {avg_val_dice_score:.4f} | '
              f'LR: {current_lr:.2e}')

        # Save best model (based on IoU)
        if avg_val_iou > best_val_iou:
            best_val_iou = avg_val_iou
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': avg_val_loss,
                'val_iou': avg_val_iou,
                'val_dice': avg_val_dice_score,
                'config': CONFIG,
                'model_info': models[model_name]
            }, f'best_{model_name.lower().replace("_", "-")}.pth')
            print(f"    [SAVED] New best model saved! (IoU: {avg_val_iou:.4f})")

    return model, history

"""## 7. Finetune All Pretrained Models"""

trained_models = {}
training_histories = {}

print(f"Starting finetuning of {len(models)} pretrained models")
print("-" * 60)

for i, (model_name, model_info) in enumerate(models.items(), 1):
    # Train the model
    trained_model, history = train_model(
        model_info['model'],
        model_name,
        train_loader,
        val_loader,
        CONFIG['num_epochs'],
        device
    )

    trained_models[model_name] = {
        'model': trained_model,
        'params': model_info['params'],
        'encoder_name': model_info['encoder_name'],
        'encoder_weights': model_info['encoder_weights']
    }
    training_histories[model_name] = history

    # Print summary for this model
    best_val_iou = max(history['val_iou'])
    best_val_dice = max(history['val_dice_score'])
    final_val_loss = history['val_loss'][-1]
    best_epoch = np.argmax(history['val_iou']) + 1

    print(f"\n{model_name} finetuning completed!")
    print(f"Best validation IoU: {best_val_iou:.4f} (epoch {best_epoch})")
    print(f"Best validation Dice: {best_val_dice:.4f}")
    print(f"Final validation loss: {final_val_loss:.4f}")

    # Clear GPU memory
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

print("\n" + "-"*60)
print("Performance summary:")

# Quick performance comparison
performance_summary = []
for model_name, history in training_histories.items():
    best_iou = max(history['val_iou'])
    best_dice = max(history['val_dice_score'])
    params = trained_models[model_name]['params']
    encoder = trained_models[model_name]['encoder_name']

    performance_summary.append({
        'model': model_name,
        'encoder': encoder,
        'iou': best_iou,
        'dice': best_dice,
        'params': params
    })

# Sort by IoU performance
performance_summary.sort(key=lambda x: x['iou'], reverse=True)

print("\nRanking by IoU performance:")
print("-" * 60)
for i, perf in enumerate(performance_summary, 1):
    rank = "[1st]" if i == 1 else "[2nd]" if i == 2 else "[3rd]" if i == 3 else f"[{i}th]"
    print(f"{rank} {i}. {perf['model']:<20} IoU: {perf['iou']:.4f} | Dice: {perf['dice']:.4f} | {perf['params']/1e6:.1f}M")

best_model = performance_summary[0]['model']
print(f"\n[BEST] Best performing model: {best_model} (IoU: {performance_summary[0]['iou']:.4f})")

"""## 8. Training Loss Curves Visualization"""

fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.flatten()

metrics = ['train_loss', 'val_loss', 'train_iou', 'val_iou', 'val_dice_score', 'learning_rates']
titles = ['Training Loss', 'Validation Loss', 'Training IoU', 'Validation IoU', 'Validation Dice Score', 'Learning Rate']
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']

for i, (metric, title) in enumerate(zip(metrics, titles)):
    ax = axes[i]

    for j, (model_name, history) in enumerate(training_histories.items()):
        epochs = range(1, len(history[metric]) + 1)

        # Special handling for learning rate (log scale)
        if metric == 'learning_rates':
            ax.semilogy(epochs, history[metric],
                       label=f'{model_name.replace("UNet_", "")}',
                       color=colors[j % len(colors)], linewidth=2, marker='o', markersize=3)
        else:
            ax.plot(epochs, history[metric],
                   label=f'{model_name.replace("UNet_", "")} ({trained_models[model_name]["params"]/1e6:.1f}M)',
                   color=colors[j % len(colors)], linewidth=2)

    # Add vertical line for encoder unfreezing
    if CONFIG['freeze_encoder_epochs'] > 0 and metric != 'learning_rates':
        ax.axvline(x=CONFIG['freeze_encoder_epochs'], color='red', linestyle='--', alpha=0.7,
                  label='Encoder Unfreeze' if i == 0 else "")

    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xlabel('Epoch')

    if metric == 'learning_rates':
        ax.set_ylabel('Learning Rate (log scale)')
    else:
        ax.set_ylabel(metric.replace('_', ' ').title())

    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)

    # Highlight best performance
    if 'val' in metric and metric != 'learning_rates':
        for model_name, history in training_histories.items():
            if metric in ['val_loss']:
                best_val = min(history[metric])
                best_epoch = np.argmin(history[metric]) + 1
            else:
                best_val = max(history[metric])
                best_epoch = np.argmax(history[metric]) + 1

            # Mark best point
            ax.scatter(best_epoch, best_val, s=100,
                      color=colors[list(training_histories.keys()).index(model_name) % len(colors)],
                      marker='*', zorder=5, edgecolors='black', linewidth=1)

plt.tight_layout()
plt.savefig('pretrained_training_curves.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nModel Performance Summary:")
print("-" * 90)
print(f"{'Model':<20} {'Encoder':<15} {'Params':<8} {'Best IoU':<10} {'Best Dice':<10} {'Final Loss':<12} {'Best Epoch':<10}")
print("-" * 90)

for model_name, history in training_histories.items():
    encoder = trained_models[model_name]['encoder_name']
    params = trained_models[model_name]['params'] / 1e6
    best_iou = max(history['val_iou'])
    best_dice = max(history['val_dice_score'])
    final_loss = history['val_loss'][-1]
    best_epoch = np.argmax(history['val_iou']) + 1

    print(f"{model_name:<20} {encoder:<15} {params:>6.1f}M {best_iou:>9.4f} {best_dice:>9.4f} {final_loss:>11.4f} {best_epoch:>9d}")

"""## 9. Model Comparison Visualization"""

def load_test_samples(num_samples=4):
    test_samples = []

    for i in range(min(num_samples, len(val_files))):
        img_name = val_files[i]

        # Load image
        img_path = os.path.join(CONFIG['images_path'], img_name)
        image = cv2.imread(img_path)
        if image is None:
            print(f"Warning: Could not load image: {img_path}")
            continue
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Load mask
        base_name = os.path.splitext(img_name)[0]
        mask_path = os.path.join(CONFIG['masks_path'], base_name + '_mask.png')
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        # Binarize mask
        mask = (mask > 127).astype(np.uint8)

        # Apply validation transform
        augmented = val_transform(image=image, mask=mask)
        image_tensor = augmented['image'].unsqueeze(0).to(device)
        mask_tensor = augmented['mask']

        test_samples.append({
            'image': image_tensor,
            'mask_tensor': mask_tensor,
            'original_image': image,
            'original_mask': mask,
            'filename': img_name
        })

    return test_samples

# Get test samples
test_samples = load_test_samples(31)
print(f"Loaded {len(test_samples)} test samples for comparison")

# Generate predictions for all models
model_predictions = {}
inference_times = {}

for model_name, model_info in trained_models.items():
    model = model_info['model']
    model.eval()

    predictions = []
    times = []

    with torch.no_grad():
        for sample in test_samples:
            start_time = torch.cuda.Event(enable_timing=True)
            end_time = torch.cuda.Event(enable_timing=True)

            start_time.record()
            pred = model(sample['image'])
            end_time.record()

            torch.cuda.synchronize()
            elapsed_time = start_time.elapsed_time(end_time)
            times.append(elapsed_time)

            pred_np = pred.cpu().squeeze().numpy()
            predictions.append(pred_np)

    model_predictions[model_name] = predictions
    inference_times[model_name] = np.mean(times)
    print(f"  [OK] {model_name}: {np.mean(times):.2f}ms avg inference time")

# Create comprehensive visualization
num_models = len(trained_models)
fig, axes = plt.subplots(len(test_samples), num_models + 2, figsize=(4*(num_models+2), 4*len(test_samples)))
if len(test_samples) == 1:
    axes = axes.reshape(1, -1)

for i, sample in enumerate(test_samples):
    # Original image
    axes[i, 0].imshow(sample['original_image'])
    axes[i, 0].set_title(f'Original\n{sample["filename"]}', fontsize=10)
    axes[i, 0].axis('off')

    # Ground truth mask (using original for visualization)
    axes[i, 1].imshow(sample['original_mask'], cmap='gray')
    axes[i, 1].set_title('Ground Truth', fontsize=10)
    axes[i, 1].axis('off')

    # Model predictions
    for j, (model_name, predictions) in enumerate(model_predictions.items()):
        pred_mask_np = (predictions[i] > 0.5).astype(np.uint8)
        axes[i, j+2].imshow(pred_mask_np, cmap='gray')

        # Calculate metrics for this sample using the transformed mask tensor
        gt_mask_tensor = sample['mask_tensor']
        pred_mask_tensor = torch.from_numpy(pred_mask_np).unsqueeze(0).float() # Convert pred to tensor

        iou = calculate_iou(pred_mask_tensor, gt_mask_tensor)
        dice = calculate_dice_score(pred_mask_tensor, gt_mask_tensor)

        # Color-code title based on performance
        color = 'green' if iou > 0.8 else 'orange' if iou > 0.6 else 'red'

        model_short = model_name.replace('UNet_', '').replace('_', ' ')
        title = f'{model_short}\nIoU: {iou:.3f}\nDice: {dice:.3f}\n{inference_times[model_name]:.1f}ms'
        axes[i, j+2].set_title(title, fontsize=9, color=color, weight='bold' if iou > 0.8 else 'normal')
        axes[i, j+2].axis('off')

plt.tight_layout()
plt.savefig('pretrained_model_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

# Performance and efficiency summary
print("\nModel Comparison Summary:")
print("=" * 80)
print(f"{'Model':<20} {'Encoder':<15} {'Params':<8} {'Inference':<10} {'Val IoU':<10} {'Val Dice':<10}")
print("=" * 80)

for model_name in trained_models.keys():
    encoder = trained_models[model_name]['encoder_name']
    params = trained_models[model_name]['params'] / 1e6
    inference_time = inference_times[model_name]
    val_iou = max(training_histories[model_name]['val_iou'])
    val_dice = max(training_histories[model_name]['val_dice_score'])

    print(f"{model_name:<20} {encoder:<15} {params:>6.1f}M {inference_time:>8.1f}ms {val_iou:>9.4f} {val_dice:>9.4f}")

print("\nLegend: Green IoU > 0.8, Orange IoU > 0.6, Red IoU ≤ 0.6")

# Set device to CPU
device_cpu = torch.device('cpu')
print(f"Using device: {device_cpu}")
import time
def load_test_samples_cpu(num_samples=4):
    test_samples = []

    for i in range(min(num_samples, len(val_files))):
        img_name = val_files[i]

        # Load image
        img_path = os.path.join(CONFIG['images_path'], img_name)
        image = cv2.imread(img_path)
        if image is None:
            print(f"Warning: Could not load image: {img_path}")
            continue
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Load mask
        base_name = os.path.splitext(img_name)[0]
        mask_path = os.path.join(CONFIG['masks_path'], base_name + '_mask.png')
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        # Binarize mask
        mask = (mask > 127).astype(np.uint8)

        # Apply validation transform
        augmented = val_transform(image=image, mask=mask)
        image_tensor = augmented['image'].unsqueeze(0).to(device_cpu) # Transfer to CPU
        mask_tensor = augmented['mask']

        test_samples.append({
            'image': image_tensor,
            'mask_tensor': mask_tensor,
            'original_image': image,
            'original_mask': mask,
            'filename': img_name
        })

    return test_samples

# Get test samples
test_samples_cpu = load_test_samples_cpu(31)
print(f"Loaded {len(test_samples_cpu)} test samples for comparison on CPU")

# Generate predictions for all models on CPU
model_predictions_cpu = {}
inference_times_cpu = {}

for model_name, model_info in trained_models.items():
    model = model_info['model'].to(device_cpu) # Transfer model to CPU
    model.eval()

    predictions = []
    times = []

    with torch.no_grad():
        for sample in test_samples_cpu:
            # Use time.time() for CPU timing
            start_time = time.time()
            pred = model(sample['image'])
            end_time = time.time()

            elapsed_time = (end_time - start_time) * 1000 # Convert to milliseconds
            times.append(elapsed_time)

            pred_np = pred.cpu().squeeze().numpy()
            predictions.append(pred_np)

    model_predictions_cpu[model_name] = predictions
    inference_times_cpu[model_name] = np.mean(times)
    print(f"  [OK] {model_name}: {np.mean(times):.2f}ms avg inference time (CPU)")

# Create comprehensive visualization (using CPU results)
num_models = len(trained_models)
fig, axes = plt.subplots(len(test_samples_cpu), num_models + 2, figsize=(4*(num_models+2), 4*len(test_samples_cpu)))
if len(test_samples_cpu) == 1:
    axes = axes.reshape(1, -1)

for i, sample in enumerate(test_samples_cpu):
    # Original image
    axes[i, 0].imshow(sample['original_image'])
    axes[i, 0].set_title(f'Original\n{sample["filename"]}', fontsize=10)
    axes[i, 0].axis('off')

    # Ground truth mask (using original for visualization)
    axes[i, 1].imshow(sample['original_mask'], cmap='gray')
    axes[i, 1].set_title('Ground Truth', fontsize=10)
    axes[i, 1].axis('off')

    # Model predictions
    for j, (model_name, predictions) in enumerate(model_predictions_cpu.items()):
        pred_mask_np = (predictions[i] > 0.5).astype(np.uint8)
        axes[i, j+2].imshow(pred_mask_np, cmap='gray')

        # Calculate metrics for this sample using the transformed mask tensor
        gt_mask_tensor = sample['mask_tensor']
        pred_mask_tensor = torch.from_numpy(pred_mask_np).unsqueeze(0).float() # Convert pred to tensor

        iou = calculate_iou(pred_mask_tensor, gt_mask_tensor)
        dice = calculate_dice_score(pred_mask_tensor, gt_mask_tensor)

        # Color-code title based on performance
        color = 'green' if iou > 0.8 else 'orange' if iou > 0.6 else 'red'

        model_short = model_name.replace('UNet_', '').replace('_', ' ')
        title = f'{model_short}\nIoU: {iou:.3f}\nDice: {dice:.3f}\n{inference_times_cpu[model_name]:.1f}ms'
        axes[i, j+2].set_title(title, fontsize=9, color=color, weight='bold' if iou > 0.8 else 'normal')
        axes[i, j+2].axis('off')

plt.tight_layout()
plt.savefig('pretrained_model_comparison_cpu.png', dpi=300, bbox_inches='tight')
plt.show()

# Performance and efficiency summary (using CPU results)
print("\nModel Comparison Summary (CPU):")
print("=" * 80)
print(f"{'Model':<20} {'Encoder':<15} {'Params':<8} {'Inference (CPU)':<15} {'Val IoU':<10} {'Val Dice':<10}")
print("=" * 80)

for model_name in trained_models.keys():
    encoder = trained_models[model_name]['encoder_name']
    params = trained_models[model_name]['params'] / 1e6
    inference_time = inference_times_cpu[model_name]
    val_iou = max(training_histories[model_name]['val_iou']) # Use existing validation results
    val_dice = max(training_histories[model_name]['val_dice_score']) # Use existing validation results

    print(f"{model_name:<20} {encoder:<15} {params:>6.1f}M {inference_time:>14.1f}ms {val_iou:>9.4f} {val_dice:>9.4f}")

print("\nLegend: Green IoU > 0.8, Orange IoU > 0.6, Red IoU ≤ 0.6")

"""## 10. Test Visualization"""

# Interactive test visualization for vibe checking
def visualize_random_predictions(num_samples=8):
    # Get random samples from validation set
    random_indices = np.random.choice(len(val_files), num_samples, replace=False)

    # Select best performing model for testing
    best_model_name = max(training_histories.keys(),
                         key=lambda x: max(training_histories[x]['val_iou']))
    best_model = trained_models[best_model_name]['model']
    best_model.eval()

    best_iou = max(training_histories[best_model_name]['val_iou'])
    best_encoder = trained_models[best_model_name]['encoder_name']

    print(f"Using best model: {best_model_name}")
    print(f"Encoder: {best_encoder} | Validation IoU: {best_iou:.4f}")
    print(f"Testing on {num_samples} random validation samples...")

    fig, axes = plt.subplots(2, num_samples//2, figsize=(20, 10))
    axes = axes.flatten()

    total_iou = 0
    total_dice = 0
    sample_metrics = []

    for i, idx in enumerate(random_indices):
        img_name = val_files[idx]

        # Load and preprocess
        img_path = os.path.join(CONFIG['images_path'], img_name)
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        base_name = os.path.splitext(img_name)[0]
        mask_path = os.path.join(CONFIG['masks_path'], base_name + '_mask.png')
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = (mask > 127).astype(np.uint8)

        # Apply validation transform to both image and mask
        augmented = val_transform(image=image, mask=mask)
        image_tensor = augmented['image'].unsqueeze(0).to(device)
        # Use the transformed mask for metric calculation and visualization overlay
        mask_transformed = augmented['mask'].squeeze().numpy()


        with torch.no_grad():
            pred = best_model(image_tensor)
            pred_np = pred.cpu().squeeze().numpy()
            pred_mask = (pred_np > 0.5).astype(np.uint8)

        # Calculate comprehensive metrics using the transformed mask
        intersection = np.logical_and(mask_transformed, pred_mask).sum()
        union = np.logical_or(mask_transformed, pred_mask).sum()
        iou = intersection / union if union > 0 else 1.0

        dice = (2 * intersection) / (mask_transformed.sum() + pred_mask.sum()) if (mask_transformed.sum() + pred_mask.sum()) > 0 else 1.0

        # Calculate pixel accuracy
        correct_pixels = np.sum(mask_transformed == pred_mask)
        total_pixels = mask_transformed.size
        pixel_accuracy = correct_pixels / total_pixels

        total_iou += iou
        total_dice += dice
        sample_metrics.append({'iou': iou, 'dice': dice, 'pixel_acc': pixel_accuracy})

        # Create sophisticated overlay visualization
        # Resize original image to match the transformed mask dimensions for overlay
        image_resized = cv2.resize(image, (mask_transformed.shape[1], mask_transformed.shape[0])).astype(np.float32)
        overlay = image_resized.copy()

        # Create colored overlay: GT in green, prediction in red, overlap in yellow
        gt_mask = mask_transformed > 0
        pred_mask_bool = pred_mask > 0
        overlap = np.logical_and(gt_mask, pred_mask_bool)

        # False negatives (missed by prediction) in blue
        false_negative = np.logical_and(gt_mask, ~pred_mask_bool)
        # False positives (wrong prediction) in magenta
        false_positive = np.logical_and(~gt_mask, pred_mask_bool)

        # Apply colors
        overlay[overlap] = [255, 255, 0]     # Yellow for correct prediction
        overlay[false_negative] = [0, 100, 255]  # Blue for missed regions
        overlay[false_positive] = [255, 0, 255]  # Magenta for false alarms

        # Blend with original image
        alpha = 0.4
        result = cv2.addWeighted(image_resized, 1-alpha, overlay, alpha, 0)
        result = np.clip(result, 0, 255).astype(np.uint8)

        axes[i].imshow(result)

        # Color-coded title based on performance
        if iou > 0.8:
            title_color = 'green'
            performance_indicator = '[EXCELLENT]'
        elif iou > 0.6:
            title_color = 'orange'
            performance_indicator = '[GOOD]'
        elif iou > 0.4:
            title_color = 'orange'
            performance_indicator = '[MODERATE]'
        else:
            title_color = 'red'
            performance_indicator = '[POOR]'


        title = f'{performance_indicator} Sample {i+1}\nIoU: {iou:.3f} | Dice: {dice:.3f}\nAcc: {pixel_accuracy:.3f}'
        axes[i].set_title(title, fontsize=10, color=title_color, weight='bold')
        axes[i].axis('off')

    avg_iou = total_iou / num_samples
    avg_dice = total_dice / num_samples
    avg_pixel_acc = np.mean([m['pixel_acc'] for m in sample_metrics])

    # Add comprehensive legend and statistics
    legend_text = (
        f'Yellow: Correct Prediction  Blue: Missed (False Neg)  Magenta: False Alarm (False Pos)\n'
        f'Model: {best_model_name} | Encoder: {best_encoder}\n'
        f'Avg IoU: {avg_iou:.4f} | Avg Dice: {avg_dice:.4f} | Avg Pixel Acc: {avg_pixel_acc:.4f}'
    )

    plt.suptitle(legend_text, fontsize=14, y=0.02, ha='center')
    plt.tight_layout()
    plt.subplots_adjust(bottom=0.15)
    plt.savefig('pretrained_vibe_check.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Comprehensive vibe check results
    print("-" * 60)
    print(f"Average IoU on {num_samples} random samples: {avg_iou:.4f}")
    print(f"Average Dice Score: {avg_dice:.4f}")
    print(f"Average Pixel Accuracy: {avg_pixel_acc:.4f}")

    # Performance distribution
    excellent = sum(1 for m in sample_metrics if m['iou'] > 0.8)
    good = sum(1 for m in sample_metrics if 0.6 < m['iou'] <= 0.8)
    moderate = sum(1 for m in sample_metrics if 0.4 < m['iou'] <= 0.6)
    poor = sum(1 for m in sample_metrics if m['iou'] <= 0.4)

    print(f"\nPerformance Distribution:")
    print(f"Excellent (IoU > 0.8): {excellent}/{num_samples} ({excellent/num_samples*100:.1f}%)")
    print(f"Good (IoU 0.6-0.8):     {good}/{num_samples} ({good/num_samples*100:.1f}%)")
    print(f"Moderate (IoU 0.4-0.6): {moderate}/{num_samples} ({moderate/num_samples*100:.1f}%)")
    print(f"Poor (IoU ≤ 0.4):       {poor}/{num_samples} ({poor/num_samples*100:.1f}%)")


    return avg_iou, avg_dice, sample_metrics

# Run the comprehensive vibe check
vibe_results = visualize_random_predictions(8)

print(f"\n[SAVED] Vibe check visualization saved as 'pretrained_vibe_check.png'")
print(f"[COMPLETE] Pretrained model finetuning and evaluation complete!")